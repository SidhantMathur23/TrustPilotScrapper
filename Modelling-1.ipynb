{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d725ce2f-e4c4-4f69-9039-e0e4bc521b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, brier_score_loss, log_loss, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os, re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e79cdce-86d9-4782-bb63-6ae61a600508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(mongodb_client, database_name, collection_name):\n",
    "    \"\"\" Reading scrapped reviews from MongoDB \"\"\"\n",
    "    # Creating list to store customer reviews\n",
    "    customer_reviews = []\n",
    "\n",
    "    # Initialize database \n",
    "    db = mongodb_client[database_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Reading collection\n",
    "    for document in collection.find():\n",
    "        if len(document) > 5: # Indicating that all the required keys are present in the dictionary\n",
    "            customer_reviews.append(document)\n",
    "        continue\n",
    "\n",
    "    return pd.DataFrame(customer_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f530b1-ea6b-499f-a322-d71c260debde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading processed reviews from MongoDB\n",
    "total_df = read_data(\n",
    "    mongodb_client = MongoClient(\"mongodb://localhost:27017/\"), \n",
    "    database_name = 'TrustPilotDatabase', collection_name = 'ProcessedReviewCollection'\n",
    ")\n",
    "\n",
    "# Renaming column names\n",
    "df = total_df[['SpellingCorrected','Rating']]\n",
    "required_df = df.rename(columns = {'SpellingCorrected' : 'Reviews'}).reset_index(drop=True)\n",
    "\n",
    "# Filtering 'None' & 'N/A' reviews from the corpus\n",
    "required_df = required_df[(required_df['Reviews']!= 'None') & (required_df['Reviews']!= 'N/A')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6490add3-ac43-4d9a-9304-bfe1cb3ae58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Class Label from Rating\n",
    "def split_rating(input_rating):\n",
    "    ''' Function to split an input rating & store it's integer class label '''\n",
    "    return int(input_rating.split()[1])\n",
    "\n",
    "# Removing extra whitespaces within reviews\n",
    "def remove_whitespaces(text):\n",
    "    \"\"\" Removing additional whitespaces\"\"\"\n",
    "    return ' '.join(sent_tokenize(text.strip()))\n",
    "\n",
    "required_df['Reviews'] = required_df['Reviews'].apply(lambda x : remove_whitespaces(x))\n",
    "required_df['Rating'] = required_df['Rating'].apply(lambda x : split_rating(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa92ca1-1628-453f-ba38-a71aff61a11f",
   "metadata": {},
   "source": [
    "### Machine Learning Modelling\n",
    "In this section, we will be performing a `train-test split` on the review dataset, in order to evaluate the fit of our machine learning models.\n",
    "Additionally, I will be using MLFlow as an experiment tracker. `MLflow` is a platform to streamline `machine learning development`, including `tracking experiments`, packaging code into reproducible runs, and `sharing and deploying models`. \n",
    "\n",
    "We will begin by assigning a `local server` with a suitable local URL: `http://127.0.0.1:5000` (in my case, but this is configurable as per the user's requirements). We will then create an` experiment` which will be visible to the developer, using the interactive MLFlow UI. \n",
    "Within, this experiment, we will be creating multiple MLFlow runs for `tracking, storing & visualizing machine learning artifacts, models & evaluation metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a2b648-4d1b-4c9f-8f57-8b4377502c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/926171415805343055', creation_time=1720605883658, experiment_id='926171415805343055', last_update_time=1720605883658, lifecycle_stage='active', name='Model Building - Without Augmentation', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up MLFlow Server for experiment tracking \n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Model Building - Without Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e28476-bb92-4325-aede-d907ce4b0f19",
   "metadata": {},
   "source": [
    "#### MLOPS - Logging dataset artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4713708a-e6cb-4451-b35a-b892eb44ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_datasets(data_dict, destination_folder_name):\n",
    "    '''\n",
    "    Functions for logging & storing features & target labels of training & test datasets as ML Artifacts.\n",
    "    Input : \n",
    "        @data_dict : Dictionary which stores the name & their respective dataframe as a key value pair\n",
    "        @destination_folder_name : Name of the folder where the datasets will be stored. (Run ID must specified, optionally)\n",
    "    '''\n",
    "    # Creating MLflow run & logging artifact to the MLflow run\n",
    "    active_directory = r\"C:\\Users\\smathur\\Desktop\\Projects\\TrustPilot\"\n",
    "    with mlflow.start_run():\n",
    "        print(\"========= Initializing logging =========\")\n",
    "        # Iterating over data_dict to store each dataframe as an artifact\n",
    "        for key, value in data_dict.items():\n",
    "            print(f'Logging {key} as an artifact...')\n",
    "            value.to_csv(key, index=False)\n",
    "            mlflow.log_artifact(key, destination_folder_name)\n",
    "\n",
    "            # Deleting the file from the current working directory \n",
    "            os.remove(os.path.join(active_directory, key))\n",
    "            print('Current working directory cleanup completed. Logging successful')\n",
    "        print(\"========= Artifact logging completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6380f3-66ae-4509-ae8d-75494cde5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting reviews into train & test sets\n",
    "X, y = required_df[['Reviews']], required_df[['Rating']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, shuffle = True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Creating a dictionary to store filenames & their respective dataframe as key value pairs\n",
    "data_info = {\n",
    "    'X_train.csv' : X_train, \n",
    "    'X_test.csv' : X_test, \n",
    "    'y_train.csv' : y_train, \n",
    "    'y_test.csv' : y_test\n",
    "}\n",
    "\n",
    "# Creating MLflow run & logging artifact to the MLflow run.\n",
    "#logging_datasets(data_dict = data_info, destination_folder_name= 'WithoutAugmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7413e3-a0a1-4e85-9c33-0d6151576c9e",
   "metadata": {},
   "source": [
    "#### Pre-Processing for Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7472622-d6cc-4e51-bd9e-6363f4be4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in training vocabulary : 1509350\n",
      "Number of unique tokens in training vocabulary : 35255\n"
     ]
    }
   ],
   "source": [
    "# Creating vocabulary\n",
    "def create_vocabulary(review_list):\n",
    "    '''\n",
    "    Function to create the vocabulary from an input list of reviews\n",
    "    Input:\n",
    "        @review_list : List of input reviews, used to create the vocabulary\n",
    "    Output:\n",
    "        vocabulary : Resulting vocabulary of the review sentences\n",
    "    '''\n",
    "    vocabulary = []\n",
    "    for review in review_list:\n",
    "        words = word_tokenize(review)\n",
    "        for word in words:\n",
    "            vocabulary.append(word)\n",
    "    return vocabulary\n",
    "\n",
    "# Building training vocabulary \n",
    "train_reviews = X_train['Reviews'].tolist()\n",
    "train_vocab = create_vocabulary(train_reviews)\n",
    "print(f'Number of tokens in training vocabulary : {len(train_vocab)}')\n",
    "print(f'Number of unique tokens in training vocabulary : {len(set(train_vocab))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e47360-4816-42e9-ad5c-59059a206614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization & Stop Word removal\n",
    "def perform_lemmatization_stop_word_removal(input_review, lemmatizer, stop_words):\n",
    "    ''' Function to perform lemmatization & removing stop words from the input review '''\n",
    "    words = word_tokenize(input_review)\n",
    "    final_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(final_words).strip()\n",
    "\n",
    "# Performing lower casing\n",
    "def lower_case(input_review):\n",
    "    ''' Function to convert an input review into lower casing '''\n",
    "    return input_review.lower()\n",
    "\n",
    "# Removing Punctuation\n",
    "def remove_punctuation(input_review):\n",
    "    ''' Removing punctuation marks from reviews'''\n",
    "    # Define the pattern to match punctuation characters\n",
    "    pattern = r\"[^\\w\\s]\"\n",
    "    # Remove punctuations using regex substitution\n",
    "    text_without_punctuation = re.sub(pattern, \"\", input_review)\n",
    "\n",
    "    # Removing additional whitespaces \n",
    "    text_words = text_without_punctuation.split()\n",
    "    return ' '.join(text_words).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9332b0ba-9336-4e0f-96f5-d21b4a27113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in new vocabulary : 791077\n",
      "Number of unique tokens in new vocabulary : 24739\n"
     ]
    }
   ],
   "source": [
    "# Instanciating lemmatizer for word normalization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_sentences = []\n",
    "\n",
    "# Pre-Processing train_sentences \n",
    "for sentence in train_reviews:\n",
    "    lemmatized_sentence = perform_lemmatization_stop_word_removal(sentence,lemmatizer, stop_words)\n",
    "    removed_punctuations = remove_punctuation(lemmatized_sentence)\n",
    "    lower_cased = lower_case(removed_punctuations)\n",
    "    processed_sentences.append(lower_cased)\n",
    "\n",
    "# Building vocabulary of pre-processed training reviews\n",
    "processed_train_vocab = create_vocabulary(processed_sentences)\n",
    "print(f'Number of tokens in new vocabulary : {len(processed_train_vocab)}')\n",
    "print(f'Number of unique tokens in new vocabulary : {len(set(processed_train_vocab))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192890e-b118-4c12-a18b-cfb5be989279",
   "metadata": {},
   "source": [
    "#### Model Building: Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd642253-80d3-40c2-9a34-3fd1cd943728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Bag-of-Words model\n",
    "vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,1))\n",
    "bow_X_train = vectorizer.fit_transform(processed_sentences)\n",
    "\n",
    "# Converting to array\n",
    "transformed_bow_X_train = bow_X_train.toarray()\n",
    "train_labels = np.array(y_train['Rating']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "669c7ecd-0acd-45e1-a9e4-2705f365cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Pre-Processing steps to test set\n",
    "test_reviews = X_test['Reviews'].tolist()\n",
    "processed_test_sentences = []\n",
    "\n",
    "# Pre-Processing train_sentences \n",
    "for sentence in test_reviews:\n",
    "    lemmatized_sentence = perform_lemmatization_stop_word_removal(sentence,lemmatizer, stop_words)\n",
    "    removed_punctuations = remove_punctuation(lemmatized_sentence)\n",
    "    lower_cased = lower_case(removed_punctuations)\n",
    "    processed_test_sentences.append(lower_cased)\n",
    "\n",
    "# Transforming pre-processed test reviews\n",
    "bow_X_test = vectorizer.transform(processed_test_sentences)\n",
    "\n",
    "# Converting to array\n",
    "transformed_bow_X_test = bow_X_test.toarray()\n",
    "test_labels = np.array(y_test['Rating']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b2ec91-038c-432c-a141-4b07f6b994d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating fit of the model\n",
    "def evaluate_model(y_true , y_pred):\n",
    "    ''' \n",
    "    Function to calculate various evaluation metrics for evaluating fit of the model\n",
    "    Input:\n",
    "        @y_true : Truth labels\n",
    "        @y_pred : Predicted labels, which is the result of a machine learning algorithm\n",
    "    Output:\n",
    "        @eval_metrics : A dictionary containing evaluation metrics for the generated predictions\n",
    "    '''\n",
    "    \n",
    "    print('Calculating global evaluation metrics...')\n",
    "    CLASS_LABELS = ['1', '2','3','4','5']\n",
    "    METRICS = ['precision', 'recall', 'f1-score'] \n",
    "    \n",
    "    eval_metrics = {\n",
    "        'Overall Accuracy' : np.round(accuracy_score(y_true, y_pred), 4) ,\n",
    "        'Overall Precision' : np.round(precision_score(y_true, y_pred,average='macro'), 5),\n",
    "        'Overall Recall' : np.round(recall_score(y_true, y_pred,average='macro'), 5),\n",
    "        'Overall F1 Score' : np.round(f1_score(y_true, y_pred,average='macro'), 5),\n",
    "    }\n",
    "    print('Calculating evaluation metrics by class label')\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    for class_key in report.keys():\n",
    "        if class_key in class_labels:\n",
    "            for metric in report[class_key].keys():\n",
    "                if metric in METRICS:\n",
    "                    key = str(class_key)+'-' + metric.capitalize()\n",
    "                    eval_metrics[key] = np.round(report[class_key][metric],5)\n",
    "    print('Evaluation metrics calculated!')\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce280d85-1e18-4843-80e5-50ac44f29cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting scikit learn model \n",
    "def fit_sklearn_model(model_name ,model_instance , X_train, y_train , X_test, y_test, base_run_name):\n",
    "    ''' \n",
    "    Utility function which accepts a machine learning algorithm as input, fits the algorithm to the training data, generates predictions,\n",
    "    calculates evaluation metrics using MLFlow runs for tracking, logging & visualizing.\n",
    "    \n",
    "    Input:\n",
    "        @model_name : Name of machine learning model\n",
    "        @model_instance : Instance of machine learning model\n",
    "        @X_train : Train feature matrix\n",
    "        @y_train : Training class labels\n",
    "        @X_test : Test feature matrix\n",
    "        @y_test : Test class labels\n",
    "        @base_run_name : Base name assigned to each MLFlow run\n",
    "    '''\n",
    "    print(f'########## {model_name} ##########')\n",
    "    assigned_run_name = base_run_name + '-' + model_name\n",
    "    with mlflow.start_run(run_name = assigned_run_name):\n",
    "        print('Fitting on training data....')\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        print('Fitting successful...Generating predictions...')\n",
    "        model_preds = model_instance.predict(X_test)\n",
    "        print('Predictions generated.')\n",
    "        eval_metrics = evaluate_model(y_true = test_labels , y_pred = logit_preds)\n",
    "        print('Logging evaluation metrics...')\n",
    "        for key , value in eval_metrics.items():\n",
    "            mlflow.log_metric(key, value)\n",
    "        print('Logging completed. Logging model...')\n",
    "        signature = infer_signature(\n",
    "            X_train, \n",
    "            model_instance.predict(X_train)\n",
    "        )\n",
    "        mlflow.sklearn.log_model(\n",
    "            model_instance, \n",
    "            model_name, \n",
    "            signature=signature\n",
    "        )\n",
    "        print('Model logging completed. Experiment successful.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cff9d97-a01c-4d57-a766-1c27d93cae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_sklearn_model(\n",
    "#     model_name = \"Logistic Regression\",\n",
    "#     model_instance = LogisticRegression(),\n",
    "#     X_train = transformed_bow_X_train,\n",
    "#     y_train = train_labels,\n",
    "#     X_test = transformed_bow_X_test,\n",
    "#     y_test = test_labels,\n",
    "#     base_run_name = \"BOW\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88c066e7-2d30-42fb-bf89-592a183c7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec\n",
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ae878-f7d9-4e18-8d21-00766716e52a",
   "metadata": {},
   "source": [
    "#### Pre-Processing for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5722f632-a888-41f7-a6cf-952219a6c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in new vocabulary : 1509729\n",
      "Number of unique tokens in new vocabulary : 26427\n"
     ]
    }
   ],
   "source": [
    "# Pre-Processing required for creating TF-IDF matrix differs slightly than the pre-processing required for creating a bag-of-words model. \n",
    "# We will not be removing stop words or punctuations from the training reviews. This is due to the fact that TF-IDF matrix will assign less weight \n",
    "# to frequently occuring tokens & more weight to uniquely occuring tokens.\n",
    "\n",
    "# Lemmatization & Stop Word removal\n",
    "def perform_lemmatization(input_review, lemmatizer, stop_words):\n",
    "    ''' Function to perform lemmatization only on the input review '''\n",
    "    words = word_tokenize(input_review)\n",
    "    final_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(final_words).strip()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tf_idf_processed_train_sentences = []\n",
    "\n",
    "# Pre-Processing train_sentences for TF-IDF \n",
    "for sentence in train_reviews:\n",
    "    lemmatized_sentence = perform_lemmatization(sentence,lemmatizer, stop_words) # Lemmatization \n",
    "    lower_cased = lower_case(lemmatized_sentence) # Lower Casing\n",
    "    tf_idf_processed_train_sentences.append(lower_cased)\n",
    "\n",
    "# Building vocabulary of TF-IDF pre-processed training reviews\n",
    "processed_tfidf_train_vocab = create_vocabulary(tf_idf_processed_train_sentences)\n",
    "print(f'Number of tokens in new vocabulary : {len(processed_tfidf_train_vocab)}')\n",
    "print(f'Number of unique tokens in new vocabulary : {len(set(processed_tfidf_train_vocab))}')\n",
    "\n",
    "\n",
    "## Creating a TF-IDF model & transforming processed tf-idf train reviews\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tfidf_X_train = tf_idf_vectorizer.fit_transform(tf_idf_processed_train_sentences)\n",
    "transformed_tfidf_X_train = tfidf_X_train.toarray() # Converting to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add37318-3fa4-45bc-84ea-950306e38f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-Processing Test reviews & converting to TF-IDF Matrix\n",
    "processed_test_sentences = []\n",
    "for sentence in test_reviews:\n",
    "    lemmatized_sentence = perform_lemmatization(sentence,lemmatizer, stop_words) # Lemmatization \n",
    "    lower_cased = lower_case(lemmatized_sentence) # Lower Casing\n",
    "    processed_test_sentences.append(lower_cased)\n",
    "\n",
    "# Transforming pre-processed test reviews\n",
    "tfidf_X_test = tf_idf_vectorizer.transform(processed_test_sentences)\n",
    "transformed_tfidf_X_test = tfidf_X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd0a3a-df9d-42c4-a554-7666b8598d2f",
   "metadata": {},
   "source": [
    "#### Model Building: Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "452fbc28-f799-4f68-9581-ca46bd440a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_sklearn_model(\n",
    "#     model_name = \"Logistic Regression\",\n",
    "#     model_instance = LogisticRegression(),\n",
    "#     X_train = transformed_tfidf_X_train,\n",
    "#     y_train = train_labels,\n",
    "#     X_test = transformed_tfidf_X_test,\n",
    "#     y_test = test_labels,\n",
    "#     base_run_name = \"TFIDF\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b15bf-69fa-4745-9ee7-08de74cc4584",
   "metadata": {},
   "source": [
    "#### Pre-Processing for GloVE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4deea-0895-4601-a766-05f06fb17885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestTrustPilot",
   "language": "python",
   "name": "testtrustpilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
